<!DOCTYPE html><html><head><meta charset="UTF-8"><title> Blue Space </title><meta name="viewport" content="width=device-width, user-scalable=no"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="shortcut icon" href="/favicon.00dce1d5.ico" type="image/x-icon"><link rel="stylesheet" href="/init.366dd74d.css"><link rel="stylesheet" href="/article.df3435a8.css"></head><body> <header id="top-container" role="navigation"> </header> <main id="main-container"> <article id="article-container"> <h1 id="article-title"> Blue Space </h1> <h2 id="article-subtitle"> Building a real-time granular engine in MaxMSP </h2> <time id="article-date"> 2020.6.08 </time> <section id="article-content-container"> <details><summary>Table of Contents</summary>
<p><div class="table-of-contents"><ul><li><a href="#aims-%26-overview">Aims & Overview</a></li><li><a href="#granular-engine">Granular Engine</a><ul><li><a href="#live-buffer">Live Buffer</a></li><li><a href="#window-(envelope)-generator">Window (Envelope) Generator</a></li></ul></li><li><a href="#conclusions">Conclusions</a></li></ul></div></p>
</details>
<h2 id="aims-%26-overview">Aims &amp; Overview</h2>
<p>In performing harp, I have often felt limited by the timbral possibilities presented in modern DAWs without the need for extensive post processing which cannot be performed in a live setting. Given time any number of transformations are possible; time stretching, texture generation, sample rate automation, etc. In my previous harp performances, the audio output was mostly playback from pre-recorded and arranged material with the live harp as a lead instrument, but one overshadowed by the extensive post processing used ‚Äì and necessary ‚Äì to create the rest of the material. As such, Blue Space provides easy access to a number of rich effects which can evolve over time or be controlled entirely by the user through MIDI and a streamlined set of controls, all in real time. The Max patch is available on my Github, and does not require any externals.</p>
<p>What is a granular synthesis, or a granulator? As defined by Curtis Rhodes:</p>
<blockquote>
<p>Granular synthesis deals with sound at a ‚Äòquantum‚Äô level: the sonic atom being the individual sample (any one of the 44100 taken in a second at the standard sampling rate).<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
</blockquote>
<p>This is applied here by taking position information from a selection within a buffer, which holds 10 seconds of live or recorded sound. This position is multiplied by a duration in milliseconds to create a ‚Äògrain‚Äô of sound. 8 grains are played simultaneously with modified phase information and noise added to the original sample position to create a more varied result. This means from any point, we can generate a never-ending sound which reflects the characteristics of that point.</p>
<p><img src="https://raw.githubusercontent.com/haelyons/Website-Content/master/BLUE%20SPACE.png" alt="overview"></p>
<h2 id="granular-engine">Granular Engine</h2>
<p>The heart of this ‚Äòfreeze‚Äô operation is the grain engine. The one used here is from Nobuyasu Sakonda‚Äôs ‚ÄòGranular Synthesis 2.5‚Äô patch released in 2000. As such Blue Space serves as a dedicated expansion to allow live input into GS 2.5, along with additional features to complement live performance (random reposition, MIDI position control, envelope modification). The 2 primary obstacles in achieving real-time functionality were creating a live buffer that can both record and playback, removing artefacts created by the grain engine‚Äôs envelope system, and designing simple controls for the relevant parameters in this system.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p><img src="https://raw.githubusercontent.com/haelyons/Website-Content/master/blue%20space/Blue-Space--Grain-Engine.jpg" alt="engine"></p>
<h3 id="live-buffer">Live Buffer</h3>
<p>The live buffer ‚Äì which holds the sound or sample which is being granulated ‚Äì has 4 simple options:</p>
<ul>
<li><strong>Play</strong>: loops through existing audio in the buffer.</li>
<li><strong>Manual</strong>: freezes the currently selected point(s). This freeze can be repositioned using the cursor, random repositioning, or position randomisation (all options on the main interface).</li>
<li><strong>Record</strong>:¬†records audio from the chosen input source through the buffer until turned off. Recording can be done with the freeze of another point still playing (Manual), or the previous content of the buffer still playing (Play).</li>
<li><strong>Live Record Toggle</strong>: sets the ‚Äòfreeze‚Äô point as the recordhead while recording, creating the truest form of ‚Äòlive granulation‚Äô.</li>
</ul>
<p>While looping a <code>buffer~</code> is simple in Max, recording based on a trigger object while overwriting the previous content of the buffer, and not creating noise in the process, was rather more difficult. The <code>karma~</code> external by Rodrigo Constanza was useful in clarifying this process, though my implementation is in native Max.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p>The picture below shows the content of the <code>playManualRecord</code> subpatch. The buttons (play, manual, record) are connected each to an inlet, numbered on the right.</p>
<p><img src="https://raw.githubusercontent.com/haelyons/Website-Content/master/blue%20space/Blue-Space--playManualRecprd.jpg" alt="pmr"></p>
<h3 id="window-(envelope)-generator">Window (Envelope) Generator</h3>
<p>This patch uses the <code>sah~</code> object (which is used for sample hold) to pass parameter changes in sync with the <code>phasor~</code> ramp, avoiding artefacts and glitches completely. To include this engine into my patch however, I had to rework the envelope system; while the use of <code>sah~</code> objects is effective in removing artefacts, it also limits the envelope possibilities; because hamming or gauss windows don‚Äôt have zero crossings, they aren‚Äôt recognised by <code>sah~</code>. Thus, I opted to use a file based system and manually edited the envelopes in Audacity to have zero crossings. The picture below shows the window menu out of presentation mode (left), and the contents of the <code>p window</code> sub-patch (left).<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></p>
<p><img src="https://raw.githubusercontent.com/haelyons/Website-Content/master/blue%20space/Blue-Space--Grain-Window.jpg" alt="window"></p>
<h2 id="conclusions">Conclusions</h2>
<p>As such, Blue Space allows for significant timbral sound modification, but lacks several features which would allow it to become a standalone performance engine, rather than a live sound processing patch. For example, the inclusion of overdubbing capability and an adjustable looping period would give the performer much more control in their output. Moreover the repositioning feature could be greatly extended, with controls for curved movement over time. Additionally porting this into a Max for Live device would let the performer run multiple granulators concurrently, each with different settings. Lastly, other granulation programs have a greater degree of customisability in the size &amp; quality of grains, and the way in which these grains can be played back, features which could be useful in a live context.</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Roads, C., 2004. Microsound. 2nd ed. Cambridge, Mass.: MIT Press, pp. 85-118. <a href="#fnref1" class="footnote-backref">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Sakonda, Nobuyasu, ‚ÄúMaxmsp Patch Downloads‚Äù, <a href="http://Formantbros.Jp">Formantbros.Jp</a>, 2000 <a href="http://formantbros.jp/sako/download.html">http://formantbros.jp/sako/download.html</a> <a href="#fnref2" class="footnote-backref">‚Ü©Ô∏é</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Constanzo, Rodrigo, Karma~, version 1 (<a href="http://www.rodrigoconstanzo.com/karma/">http://www.rodrigoconstanzo.com/karma/</a>, 2006) <a href="#fnref3" class="footnote-backref">‚Ü©Ô∏é</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Alessandretti, Stefano, ‚ÄúAbstraction Of A Real-Time Granulation System Built Into The Max/MSP Environment‚Äù, Independent, 2020, pp. 1-4 <a href="#fnref4" class="footnote-backref">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section> </section> <section id="article-navigation"> <div class="article-navigation-item article-navigation-next"> <a href="/article/1.html"> <div class="article-navigation-arrow article-navigation-next">Ôºú</div> <div class="article-navigation-content article-navigation-next"> <p class="article-navigation-title">Entropy Cleric</p> <p class="article-navigation-subtitle">Custom synthesizer and algorithmic music system in MaxMSP</p> </div> </a> </div> <div class="article-navigation-item article-navigation-prev"> <a href="/article/3.html"> <div class="article-navigation-arrow article-navigation-prev">Ôºû</div> <div class="article-navigation-content article-navigation-prev"> <p class="article-navigation-title">Interactive Dance Music II</p> <p class="article-navigation-subtitle">Embodied exploration of personalised motion-sound relationships using motion sensing and interactive ML</p> </div> </a> </div> </section> <section id="article-list-button-container"> <a href="/articles.html"> <div id="article-list-button">üìö</div> </a> </section> </article> </main> <script defer src="/init.ddb7c0df.js"></script>
</body></html>